"""Directory and file fuzzer.

Discovers hidden directories and files on web servers by testing common paths
with configurable wordlists and file extensions.
"""

import asyncio
from typing import Any
from urllib.parse import urljoin

import aiohttp

from src.core.base_module import (
    AtsModule,
    ModuleSpec,
    ModuleCategory,
    Parameter,
    ParameterType,
    OutputField,
)

WORDLIST_SMALL = [
    "admin", "login", "dashboard", "config", "backup", "test", "api",
    "uploads", "images", "css", "js", "static", "assets", "wp-admin",
    "wp-content", "administrator", "panel", "console", "phpmyadmin",
    "server-status", "robots.txt", "sitemap.xml", ".env", ".git",
    ".htaccess", "web.config", "crossdomain.xml", "favicon.ico",
]

WORDLIST_MEDIUM = WORDLIST_SMALL + [
    "cgi-bin", "scripts", "tmp", "temp", "cache", "logs", "log",
    "debug", "trace", "info", "status", "health", "metrics",
    "swagger", "docs", "documentation", "readme", "changelog",
    "install", "setup", "update", "upgrade", "maintenance",
    "db", "database", "sql", "data", "dump", "export", "import",
    "user", "users", "account", "accounts", "profile", "register",
    "auth", "oauth", "token", "session", "private", "secret",
    "internal", "intranet", "portal", "gateway", "proxy",
    "old", "new", "dev", "staging", "production", "beta", "alpha",
    "v1", "v2", "v3", "rest", "graphql", "soap", "wsdl",
    "file", "files", "upload", "download", "media", "content",
    "include", "includes", "lib", "vendor", "node_modules",
    "wp-login.php", "xmlrpc.php", "wp-json", "feed",
]

WORDLIST_LARGE = WORDLIST_MEDIUM + [
    "archive", "archives", "bak", "bkp", "conf", "config.bak",
    "htpasswd", "passwd", "shadow", "credentials", "key", "keys",
    "certificate", "cert", "ssl", "tls", "pem", "p12",
    "shell", "cmd", "command", "exec", "run", "eval",
    "monitor", "monitoring", "nagios", "zabbix", "grafana",
    "jenkins", "ci", "cd", "deploy", "deployment", "release",
    "git", "svn", "hg", "cvs", "bzr", ".gitignore", ".svn",
    "terraform", "ansible", "docker", "dockerfile", "compose",
    "kubernetes", "k8s", "helm", "chart", "manifest",
    "backup.sql", "backup.zip", "backup.tar.gz", "site.bak",
    "error", "errors", "error_log", "access_log", "debug.log",
    "app", "application", "service", "services", "microservice",
    "socket", "ws", "websocket", "realtime", "event", "events",
    "queue", "worker", "job", "jobs", "task", "tasks", "cron",
    "mail", "email", "smtp", "imap", "webmail", "roundcube",
    "ftp", "sftp", "ssh", "telnet", "remote", "vnc", "rdp",
    "cpanel", "whm", "plesk", "webmin", "ispconfig",
]


class DirectoryFuzzerModule(AtsModule):
    """Discover hidden directories and files on web servers."""

    def get_spec(self) -> ModuleSpec:
        return ModuleSpec(
            name="directory_fuzzer",
            category=ModuleCategory.PENTEST,
            description="Fuzz web servers to discover hidden directories and files using built-in wordlists",
            version="1.0.0",
            parameters=[
                Parameter(name="url", type=ParameterType.URL,
                          description="Target base URL to fuzz", required=True),
                Parameter(name="wordlist", type=ParameterType.CHOICE,
                          description="Built-in wordlist size",
                          choices=["small", "medium", "large"], default="small"),
                Parameter(name="extensions", type=ParameterType.STRING,
                          description="Comma-separated file extensions to append",
                          default=".php,.html,.txt,.bak"),
            ],
            outputs=[
                OutputField(name="found_paths", type="list", description="Discovered paths with status codes"),
                OutputField(name="summary", type="dict", description="Fuzzing summary and statistics"),
            ],
            tags=["pentest", "directory", "fuzzing", "web", "enumeration"],
            author="ATS-Toolkit",
            dangerous=False,
        )

    def validate_inputs(self, config: dict[str, Any]) -> tuple[bool, str]:
        url = config.get("url", "").strip()
        if not url:
            return False, "URL is required"
        if not url.startswith(("http://", "https://")):
            return False, "URL must start with http:// or https://"
        return True, ""

    def _get_wordlist(self, size: str) -> list[str]:
        """Return the wordlist based on size selection."""
        if size == "small":
            return WORDLIST_SMALL
        elif size == "medium":
            return WORDLIST_MEDIUM
        elif size == "large":
            return WORDLIST_LARGE
        return WORDLIST_SMALL

    def _build_paths(self, words: list[str], extensions: str) -> list[str]:
        """Build full list of paths by combining words with extensions."""
        paths = list(words)
        exts = [e.strip() for e in extensions.split(",") if e.strip()]
        for word in words:
            for ext in exts:
                ext = ext if ext.startswith(".") else f".{ext}"
                paths.append(f"{word}{ext}")
        return list(set(paths))

    async def _check_path(self, session: aiohttp.ClientSession, base_url: str,
                           path: str, semaphore: asyncio.Semaphore) -> dict[str, Any] | None:
        """Check if a path exists on the target server."""
        async with semaphore:
            url = urljoin(base_url.rstrip("/") + "/", path)
            try:
                async with session.head(url, timeout=aiohttp.ClientTimeout(total=8),
                                        ssl=False, allow_redirects=False) as resp:
                    if resp.status in (200, 201, 204, 301, 302, 307, 401, 403):
                        result = {
                            "path": f"/{path}",
                            "url": url,
                            "status_code": resp.status,
                            "content_length": resp.content_length or 0,
                        }
                        if resp.status in (301, 302, 307):
                            result["redirect_to"] = resp.headers.get("Location", "")
                        if resp.status == 200:
                            result["risk"] = "info"
                        elif resp.status == 401:
                            result["risk"] = "medium"
                            result["note"] = "Authentication required"
                        elif resp.status == 403:
                            result["risk"] = "low"
                            result["note"] = "Access forbidden but path exists"
                        else:
                            result["risk"] = "info"
                        return result
            except (aiohttp.ClientError, asyncio.TimeoutError):
                pass
            return None

    async def execute(self, config: dict[str, Any]) -> dict[str, Any]:
        url = config["url"].strip()
        wordlist_size = config.get("wordlist", "small")
        extensions = config.get("extensions", ".php,.html,.txt,.bak")

        words = self._get_wordlist(wordlist_size)
        paths = self._build_paths(words, extensions)
        self.logger.info("dirfuzz_start", url=url, paths_to_test=len(paths))

        semaphore = asyncio.Semaphore(20)
        found_paths: list[dict[str, Any]] = []

        connector = aiohttp.TCPConnector(limit=20, ssl=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            # Get baseline for 404 detection
            baseline_url = urljoin(url.rstrip("/") + "/", "thispathshouldnotexist_ats_test_7391")
            baseline_status = 404
            baseline_length = 0
            try:
                async with session.head(baseline_url, timeout=aiohttp.ClientTimeout(total=8),
                                        ssl=False) as resp:
                    baseline_status = resp.status
                    baseline_length = resp.content_length or 0
            except (aiohttp.ClientError, asyncio.TimeoutError):
                pass

            tasks = [self._check_path(session, url, path, semaphore) for path in paths]
            results = await asyncio.gather(*tasks)

            for result in results:
                if result is not None:
                    # Filter out soft-404s: same status and similar length as baseline
                    if (result["status_code"] == baseline_status and
                            baseline_status == 200 and
                            abs(result["content_length"] - baseline_length) < 100):
                        continue
                    found_paths.append(result)

        found_paths.sort(key=lambda x: x["status_code"])

        interesting = [p for p in found_paths if p["status_code"] in (200, 401)]
        summary = {
            "target_url": url,
            "wordlist_size": wordlist_size,
            "total_paths_tested": len(paths),
            "paths_found": len(found_paths),
            "interesting_paths": len(interesting),
            "status_distribution": {},
        }
        for p in found_paths:
            code = str(p["status_code"])
            summary["status_distribution"][code] = summary["status_distribution"].get(code, 0) + 1

        self.logger.info("dirfuzz_complete", found=len(found_paths), tested=len(paths))
        return {"found_paths": found_paths, "summary": summary}
